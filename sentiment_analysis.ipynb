{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimentanalyse von Plenarprotokollen mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Dokument dient zum Erkunden der Datensätze, die mithilfe der in diesem Ordner verfügbaren Skriptdateien ``process_pp.py`` und ``dictionary_analysis.py`` erstellt wurden. Der größte Teil der Rechenarbeit wurde also mithilfe dieser Skripte bereits durchgeführt. Das Laden des aufbereiteten Datensatzes kann trotzdem einige Minuten dauern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst sollen alle im Folgenden benötigte Python-Pakete geladen werden. Mit dem Code in der nächsten Zelle kann überprüft werden, ob diese Pakete installiert sind. Zusätzlich wird ein deutsches Sprachmodell ``de_core_news_sm`` für spaCy heruntergeladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install spacy pandas seaborn matplotlib\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes werden die installierten Pakete für das aktuelle Skript importiert und das Sprachmodell verfügbar gemacht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import operator\n",
    "import seaborn\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden die für die Analyse nötigen Daten eingelesen. Dieser Prozess kann einige Zeit und Speicher in Anspruch nehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dateien = glob(\"plenarprotokolle/pp19/*.xml.spacy.sentiment\")\n",
    "spacy_db = {}\n",
    "for protokoll in dateien:\n",
    "    protokoll_daten = DocBin(store_user_data=True).from_bytes(open(protokoll, \"rb\").read())\n",
    "    protokoll_daten = list(protokoll_daten.get_docs(nlp.vocab))\n",
    "    spacy_db[protokoll] = protokoll_daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grundlegende Statistiken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind alle für die Analyse nötigen Ressourcen verfügbar. Zum Einen kann jetzt natürlich mit diesen experimentiert werden, zum Anderen bietet der Rest dieses Dokuments eine Führung durch beispielhafte Analysevorgänge. Zum Beispiel können grundlegende Statistiken zum Datensatz zusammengestellt werden, wie dessen allgemeiner Umfang:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Der Datensatz enthält\", len(spacy_db), \"Protokolle.\")\n",
    "\n",
    "anzahl_reden = 0\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    for rede in protokoll:\n",
    "        anzahl_reden += 1\n",
    "print(\"Diese Protokolle enthalten insgesamt\", anzahl_reden, \"Reden.\")\n",
    "\n",
    "anzahl_token = 0\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    for rede in protokoll:\n",
    "        anzahl_token += len(rede)\n",
    "print(\"Diese Reden enthalten insgesamt\", anzahl_token, \"Token.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine andere Möglichkeit ist ein Überblick über die Verteilung der Reden und Redner auf Parteien. Hierzu sollten wir aus den Daten zunächst eine entsprechende Sammlung zusammenstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "redner_parteien = {}\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    for rede in protokoll:\n",
    "        partei = rede.user_data[\"meta\"][\"redner_partei\"]\n",
    "        redner = rede.user_data[\"meta\"][\"redner_name\"]\n",
    "        if not partei in redner_parteien.keys():\n",
    "            redner_parteien[partei] = [redner]\n",
    "        else:\n",
    "            redner_parteien[partei].append(redner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for partei, namen in redner_parteien.items():\n",
    "    print(\"Abgeordnete der Partei\", partei, \"sprachen\", len(namen), \"mal (\" + \"%.2f\" % round((len(namen)/anzahl_reden)*100, 2), \"%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "redneranzahl_parteien = {}\n",
    "for partei,namen in redner_parteien.items():\n",
    "    redneranzahl_parteien[partei] = len(namen)\n",
    "redneranzahl_parteien = pd.DataFrame(redneranzahl_parteien.items(), columns=[\"partei\",\"anzahl_reden\"]).set_index(\"partei\")\n",
    "redneranzahl_parteien.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Indem wir das Wörterbuch weiterverarbeiten, können wir sowohl herausfinden, wie viele Male die jeweiligen Redner sprachen, und wie viele Redner für jede Partei sprachen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "redner_parteien_unik = {}\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    for rede in protokoll:\n",
    "        partei = rede.user_data[\"meta\"][\"redner_partei\"]\n",
    "        redner = rede.user_data[\"meta\"][\"redner_name\"]\n",
    "        if not partei in redner_parteien_unik.keys():\n",
    "            redner_parteien_unik[partei] = {}\n",
    "            redner_parteien_unik[partei][redner] = 1\n",
    "        else:\n",
    "            if not redner in redner_parteien_unik[partei]:\n",
    "                redner_parteien_unik[partei][redner] = 1\n",
    "            else:\n",
    "                redner_parteien_unik[partei][redner] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for partei, namen in redner_parteien_unik.items():\n",
    "    print(\"Für die Partei\", partei, \"sprachen\", len(namen), \"verschiedene Redner.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for partei, namen in redner_parteien_unik.items():\n",
    "    top_redner = max(namen.items(), key=operator.itemgetter(1))\n",
    "    print(\"Fleißigster Redner für die Partei\", partei, \"war\", top_redner[0], \"mit\", top_redner[1], \"Wortmeldungen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Sentimentanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An dieser Stelle sollen einige Beispiele für tatsächliche Sentimentanalyse veranschaulicht werden, angefangen mit den durchschnittlichen Polaritätswerten nach Partei und dem positivsten bzw. negativsten Redner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Zuerst sollen die Polaritätswerte nach Parteien veranschaulicht werden.\n",
    "\n",
    "Für eine vernünftige Vergleichbarkeit werden zunächst die Polaritätswerte normalisiert, indem sie verhundertfacht und anschließend mit der Länge der Rede verrechnet werden. Reden, in denen keines der Token in SentiWS gefunden wurde, werden nicht in die Analyse miteinbezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partei_sentiws_werte = {}\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    for rede in protokoll:\n",
    "        partei = rede.user_data[\"meta\"][\"redner_partei\"]\n",
    "        sentiws_score = rede.user_data[\"sentiws\"][\"sentiment_score\"]\n",
    "        laenge = len(rede)\n",
    "        if not laenge == 0 and not len(rede.user_data[\"sentiws\"]) <= 1:\n",
    "            score_relativ = round((sentiws_score/laenge)*100, 3)\n",
    "            if not partei in partei_sentiws_werte.keys():\n",
    "                partei_sentiws_werte[partei] = [score_relativ]\n",
    "            else:\n",
    "                partei_sentiws_werte[partei].append(score_relativ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for partei, sentiment_werte in partei_sentiws_werte.items():\n",
    "    print(\"Reden von Abgeordneten der Partei\", partei, \"haben eine durchschnittliche Polarität von\", round(sum(sentiment_werte)/len(sentiment_werte), 3), \", maximal\", max(sentiment_werte), \"und minimal\", min(sentiment_werte), \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partei_sentiws_werte_df = pd.DataFrame(partei_sentiws_werte.items(), columns=[\"partei\",\"werte\"])\n",
    "partei_sentiws_werte_df = partei_sentiws_werte_df.explode(\"werte\")\n",
    "partei_sentiws_werte_df[\"werte\"] = pd.to_numeric(partei_sentiws_werte_df[\"werte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partei_sentiws_werte_plot = seaborn.violinplot(y=\"werte\", x=\"partei\", data=partei_sentiws_werte_df, saturation=0.8)\n",
    "partei_sentiws_werte_plot.set_xticklabels([\"Unbekannt\",\"AfD\",\"CDU\",\"FDP\",\"LINKE\",\"GRÜNE\",\"SPD\",\"CSU\",\"Parteilos\"])\n",
    "partei_sentiws_werte_plot.set(xlabel=\"\", ylabel=\"Durchschn. Polarität\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Das gleiche lässt sich jedoch auch ohne Normalisierung der Polaritätswerte durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partei_sentiws_werte = {}\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    for rede in protokoll:\n",
    "        partei = rede.user_data[\"meta\"][\"redner_partei\"]\n",
    "        sentiws_score = rede.user_data[\"sentiws\"][\"sentiment_score\"]\n",
    "        laenge = len(rede)\n",
    "        if not laenge == 0 and not len(rede.user_data[\"sentiws\"]) <= 1:\n",
    "            if not partei in partei_sentiws_werte.keys():\n",
    "                partei_sentiws_werte[partei] = [sentiws_score]\n",
    "            else:\n",
    "                partei_sentiws_werte[partei].append(sentiws_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partei_sentiws_werte_df = pd.DataFrame(partei_sentiws_werte.items(), columns=[\"partei\",\"werte\"])\n",
    "partei_sentiws_werte_df = partei_sentiws_werte_df.explode(\"werte\")\n",
    "partei_sentiws_werte_df[\"werte\"] = pd.to_numeric(partei_sentiws_werte_df[\"werte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "partei_sentiws_werte_plot = seaborn.violinplot(y=\"werte\", x=\"partei\", data=partei_sentiws_werte_df, saturation=0.8)\n",
    "partei_sentiws_werte_plot.set_xticklabels([\"Unbekannt\",\"AfD\",\"CDU\",\"FDP\",\"LINKE\",\"GRÜNE\",\"SPD\",\"CSU\",\"Parteilos\"])\n",
    "partei_sentiws_werte_plot.set(xlabel=\"\", ylabel=\"Durchschn. Polarität\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyse von Entitäten\n",
    "Als nächstes wird ein Katalog aller im Korpus vorkommender Entitäten erstellt. Anschließend werden diesen die Polaritätswerte der Reden zugeordnet, in denen sie vorkommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ents_sentiment = {}\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    for rede in protokoll:\n",
    "        ents = list(set(rede.user_data[\"entitaeten\"]))\n",
    "        sentiment = rede.user_data[\"sentiws\"][\"sentiment_score\"]\n",
    "        for ent in ents:\n",
    "            ent = re.sub('[^A-Za-z0-9\\- ,äöüÄÖÜß]+', '', ent)\n",
    "            if not nlp.vocab[ent].is_stop and not nlp.vocab[ent.lower()].is_stop and len(ent) > 2:\n",
    "                if not ent in ents_sentiment.keys():\n",
    "                    ents_sentiment[ent] = [sentiment]\n",
    "                else:\n",
    "                    ents_sentiment[ent].append(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An dieser Stelle sollen die mit den Entitäten verbundenen Reden auf mehrere Arten untersucht werden. Erstens können die durchschnittlichen Polaritätswerte für Reden gemessen werden, in denen die Entität vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ents_sentiment_avg = {ent: sum(sentiment)/len(sentiment) for ent, sentiment in ents_sentiment.items() if len(sentiment) >= 25}\n",
    "ents_sentiment_avg_df = pd.DataFrame(ents_sentiment_avg.items(), columns=[\"ent\",\"sentiment\"]).set_index(\"ent\")\n",
    "ents_sentiment_avg_df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sind z.B. die 10 Entitäten in den positivsten Reden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ents_sentiment_avg_df.sort_values(\"sentiment\").tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andererseits kann auch die Variabilität der Redensentimente, also negativste Rede minus positivste Rede, ermittelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_sentiment_span = {ent: abs(min(sentiment)-max(sentiment)) for ent, sentiment in ents_sentiment.items() if len(sentiment) >= 5}\n",
    "ents_sentiment_span_df = pd.DataFrame(ents_sentiment_span.items(), columns=[\"ent\",\"sentiment\"]).set_index(\"ent\")\n",
    "seaborn.violinplot(y=\"sentiment\", data=ents_sentiment_span_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oder die mit den Hauptthemen, also Entitäten, die in mehr als 50 Reden im Korpus vorkommen, verbundenen Sentimente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_sentiment_hauptthemen = {ent: sum(sentiment)/len(sentiment) for ent, sentiment in ents_sentiment.items() if len(sentiment) >= 50}\n",
    "ents_sentiment_hauptthemen_df = pd.DataFrame(ents_sentiment_hauptthemen.items(), columns=[\"ent\",\"sentiment\"]).set_index(\"ent\")\n",
    "seaborn.violinplot(y=\"sentiment\", data=ents_sentiment_hauptthemen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Polaritätswerte im Laufe der Zeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch diachronisch können Polaritäten betrachtet werden: z.B. für Reden, die die Entitäten *Syrien* und *Europa* erwähnen, im Laufe der Wahlperiode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sitzung_sentiws_syrien = {}\n",
    "sitzung_sentiws_europa = {}\n",
    "\n",
    "for datei, protokoll in spacy_db.items():\n",
    "    sitzungsnr = protokoll[0].user_data[\"meta\"][\"sitzungsnr\"]\n",
    "    for rede in protokoll:\n",
    "        if \"Syrien\" in rede.user_data[\"entitaeten\"]:\n",
    "            sentiws_score = rede.user_data[\"sentiws\"][\"sentiment_score\"]\n",
    "            laenge = len(rede)\n",
    "            if not laenge == 0 and not len(rede.user_data[\"sentiws\"]) <= 1:\n",
    "                if not sitzungsnr in sitzung_sentiws_syrien.keys():\n",
    "                    sitzung_sentiws_syrien[sitzungsnr] = [sentiws_score]\n",
    "                else:\n",
    "                    sitzung_sentiws_syrien[sitzungsnr].append(sentiws_score)\n",
    "        if \"Europa\" in rede.user_data[\"entitaeten\"]:\n",
    "            sentiws_score = rede.user_data[\"sentiws\"][\"sentiment_score\"]\n",
    "            laenge = len(rede)\n",
    "            if not laenge == 0 and not len(rede.user_data[\"sentiws\"]) <= 1:\n",
    "                if not sitzungsnr in sitzung_sentiws_europa.keys():\n",
    "                    sitzung_sentiws_europa[sitzungsnr] = [sentiws_score]\n",
    "                else:\n",
    "                    sitzung_sentiws_europa[sitzungsnr].append(sentiws_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend können diese in einen Datensatz zusammengeführt werden visualisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sitzung_sentiws_syrien_df = pd.DataFrame(sitzung_sentiws_syrien.items(), columns=[\"sitzung\",\"sentiment_syrien\"]).set_index(\"sitzung\")\n",
    "sitzung_sentiws_europa_df = pd.DataFrame(sitzung_sentiws_europa.items(), columns=[\"sitzung\",\"sentiment_europa\"]).set_index(\"sitzung\")\n",
    "sitzung_sentiws = sitzung_sentiws_syrien_df.join(sitzung_sentiws_europa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seaborn.set(style=\"white\", rc={'figure.figsize':(12,6)})\n",
    "plot = seaborn.lineplot(data=sitzung_sentiws)\n",
    "plt.setp(plot.set_xticklabels([]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
